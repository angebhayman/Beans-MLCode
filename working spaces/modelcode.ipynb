{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.833333</td>\n",
       "      <td>2017</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>87.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>92.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>2017</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_rating  year    Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9  \\\n",
       "0        6.833333  2017  94.0  94.0  98.0  95.0  97.0  97.0  95.0  94.0  98.0   \n",
       "1        8.000000  2017  87.0  90.0  97.0  92.0  94.0  96.0  94.0  95.0  92.0   \n",
       "2        6.000000  2017  92.0  96.0  99.0  98.0  97.0  98.0  99.0  98.0  96.0   \n",
       "3        6.800000  2017  98.0  99.0  98.0  98.0  98.0  98.0  98.0  96.0  98.0   \n",
       "4        7.000000  2017  90.0  90.0  95.0  91.0  95.0  94.0  89.0  90.0  91.0   \n",
       "\n",
       "    Q10   Q11   Q12   Q13   Q14   Q15   Q16   Q17   Q18  \n",
       "0  96.0  96.0  96.0  96.0  98.0  94.0  94.0  96.0  89.0  \n",
       "1  92.0  89.0  97.0  95.0  91.0  94.0  95.0  94.0  88.0  \n",
       "2  97.0  96.0  98.0  98.0  98.0  98.0  96.0  98.0  89.0  \n",
       "3  97.0  99.0  97.0  99.0  99.0  99.0  96.0  97.0  91.0  \n",
       "4  90.0  90.0  89.0  90.0  94.0  92.0  91.0  96.0  90.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('../data/final_df_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>...</th>\n",
       "      <th>Q9_lag_1</th>\n",
       "      <th>Q10_lag_1</th>\n",
       "      <th>Q11_lag_1</th>\n",
       "      <th>Q12_lag_1</th>\n",
       "      <th>Q13_lag_1</th>\n",
       "      <th>Q14_lag_1</th>\n",
       "      <th>Q15_lag_1</th>\n",
       "      <th>Q16_lag_1</th>\n",
       "      <th>Q17_lag_1</th>\n",
       "      <th>Q18_lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>87.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>92.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>2017</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>2017</td>\n",
       "      <td>93.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>7.375000</td>\n",
       "      <td>2022</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>7.478261</td>\n",
       "      <td>2022</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>6.967742</td>\n",
       "      <td>2022</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>6.992000</td>\n",
       "      <td>2022</td>\n",
       "      <td>82.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>7.601504</td>\n",
       "      <td>2022</td>\n",
       "      <td>89.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3921 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      average_rating  year     Q1    Q2     Q3    Q4     Q5     Q6     Q7  \\\n",
       "1           8.000000  2017   87.0  90.0   97.0  92.0   94.0   96.0   94.0   \n",
       "2           6.000000  2017   92.0  96.0   99.0  98.0   97.0   98.0   99.0   \n",
       "3           6.800000  2017   98.0  99.0   98.0  98.0   98.0   98.0   98.0   \n",
       "4           7.000000  2017   90.0  90.0   95.0  91.0   95.0   94.0   89.0   \n",
       "5           7.400000  2017   93.0  96.0   98.0  95.0   98.0   97.0   97.0   \n",
       "...              ...   ...    ...   ...    ...   ...    ...    ...    ...   \n",
       "3917        7.375000  2022  100.0  99.0  100.0  99.0  100.0  100.0  100.0   \n",
       "3918        7.478261  2022   96.0  94.0   98.0  93.0   98.0   93.0   93.0   \n",
       "3919        6.967742  2022   86.0  91.0   98.0  88.0   96.0   96.0   91.0   \n",
       "3920        6.992000  2022   82.0  75.0   92.0  81.0  100.0   93.0   93.0   \n",
       "3921        7.601504  2022   89.0  94.0   97.0  90.0   98.0   94.0   93.0   \n",
       "\n",
       "         Q8  ...  Q9_lag_1  Q10_lag_1  Q11_lag_1  Q12_lag_1  Q13_lag_1  \\\n",
       "1      95.0  ...      98.0       96.0       96.0       96.0       96.0   \n",
       "2      98.0  ...      92.0       92.0       89.0       97.0       95.0   \n",
       "3      96.0  ...      96.0       97.0       96.0       98.0       98.0   \n",
       "4      90.0  ...      98.0       97.0       99.0       97.0       99.0   \n",
       "5      97.0  ...      91.0       90.0       90.0       89.0       90.0   \n",
       "...     ...  ...       ...        ...        ...        ...        ...   \n",
       "3917  100.0  ...      90.0       88.0       88.0       94.0       91.0   \n",
       "3918   93.0  ...     100.0       99.0       99.0      100.0       99.0   \n",
       "3919   92.0  ...      98.0       94.0       92.0       91.0       93.0   \n",
       "3920   93.0  ...      94.0       87.0       97.0       89.0       89.0   \n",
       "3921   94.0  ...      85.0       89.0      100.0      100.0      100.0   \n",
       "\n",
       "      Q14_lag_1  Q15_lag_1  Q16_lag_1  Q17_lag_1  Q18_lag_1  \n",
       "1          98.0       94.0       94.0       96.0       89.0  \n",
       "2          91.0       94.0       95.0       94.0       88.0  \n",
       "3          98.0       98.0       96.0       98.0       89.0  \n",
       "4          99.0       99.0       96.0       97.0       91.0  \n",
       "5          94.0       92.0       91.0       96.0       90.0  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "3917       97.0       95.0       93.0       95.0       21.0  \n",
       "3918      100.0       99.0       99.0       99.0        8.0  \n",
       "3919       92.0       96.0       98.0       98.0        9.0  \n",
       "3920       92.0       94.0       89.0       93.0       26.0  \n",
       "3921       82.0      100.0       69.0       92.0       56.0  \n",
       "\n",
       "[3921 rows x 40 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of data with lagged features\n",
    "\n",
    "lag = 1  \n",
    "df_lag = df.copy()\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['Year', 'Pavement Rating']:\n",
    "        df_lag[f'{col}_lag_{lag}'] = df_lag[col].shift(lag)\n",
    "\n",
    "df_lag.dropna() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>...</th>\n",
       "      <th>Q14_rolling_mean_3</th>\n",
       "      <th>Q14_rolling_std_3</th>\n",
       "      <th>Q15_rolling_mean_3</th>\n",
       "      <th>Q15_rolling_std_3</th>\n",
       "      <th>Q16_rolling_mean_3</th>\n",
       "      <th>Q16_rolling_std_3</th>\n",
       "      <th>Q17_rolling_mean_3</th>\n",
       "      <th>Q17_rolling_std_3</th>\n",
       "      <th>Q18_rolling_mean_3</th>\n",
       "      <th>Q18_rolling_std_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>92.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>4.041452</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>2.309401</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.800000</td>\n",
       "      <td>2017</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.358899</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>89.333333</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>2.645751</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>3.785939</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>2.886751</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>2017</td>\n",
       "      <td>93.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>2.516611</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.428571</td>\n",
       "      <td>2017</td>\n",
       "      <td>86.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>2.886751</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>95.666667</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>2.516611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>7.375000</td>\n",
       "      <td>2022</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>11.060440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>7.478261</td>\n",
       "      <td>2022</td>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>4.041452</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>97.333333</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>7.234178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>6.967742</td>\n",
       "      <td>2022</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.666667</td>\n",
       "      <td>4.618802</td>\n",
       "      <td>96.333333</td>\n",
       "      <td>2.516611</td>\n",
       "      <td>95.333333</td>\n",
       "      <td>5.507571</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>10.115994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>6.992000</td>\n",
       "      <td>2022</td>\n",
       "      <td>82.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>5.773503</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.055050</td>\n",
       "      <td>85.333333</td>\n",
       "      <td>14.843629</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>3.214550</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>23.797759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>7.601504</td>\n",
       "      <td>2022</td>\n",
       "      <td>89.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>7.211103</td>\n",
       "      <td>96.666667</td>\n",
       "      <td>3.055050</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>13.228757</td>\n",
       "      <td>93.333333</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>18.929694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3920 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      average_rating  year     Q1    Q2     Q3    Q4     Q5     Q6     Q7  \\\n",
       "2           6.000000  2017   92.0  96.0   99.0  98.0   97.0   98.0   99.0   \n",
       "3           6.800000  2017   98.0  99.0   98.0  98.0   98.0   98.0   98.0   \n",
       "4           7.000000  2017   90.0  90.0   95.0  91.0   95.0   94.0   89.0   \n",
       "5           7.400000  2017   93.0  96.0   98.0  95.0   98.0   97.0   97.0   \n",
       "6           8.428571  2017   86.0  88.0   96.0  91.0   93.0   90.0   90.0   \n",
       "...              ...   ...    ...   ...    ...   ...    ...    ...    ...   \n",
       "3917        7.375000  2022  100.0  99.0  100.0  99.0  100.0  100.0  100.0   \n",
       "3918        7.478261  2022   96.0  94.0   98.0  93.0   98.0   93.0   93.0   \n",
       "3919        6.967742  2022   86.0  91.0   98.0  88.0   96.0   96.0   91.0   \n",
       "3920        6.992000  2022   82.0  75.0   92.0  81.0  100.0   93.0   93.0   \n",
       "3921        7.601504  2022   89.0  94.0   97.0  90.0   98.0   94.0   93.0   \n",
       "\n",
       "         Q8  ...  Q14_rolling_mean_3  Q14_rolling_std_3  Q15_rolling_mean_3  \\\n",
       "2      98.0  ...           95.666667           4.041452           95.333333   \n",
       "3      96.0  ...           96.000000           4.358899           97.000000   \n",
       "4      90.0  ...           97.000000           2.645751           96.333333   \n",
       "5      97.0  ...           96.666667           2.516611           96.000000   \n",
       "6      89.0  ...           96.000000           1.732051           93.666667   \n",
       "...     ...  ...                 ...                ...                 ...   \n",
       "3917  100.0  ...           97.000000           3.000000           97.333333   \n",
       "3918   93.0  ...           96.333333           4.041452           96.666667   \n",
       "3919   92.0  ...           94.666667           4.618802           96.333333   \n",
       "3920   93.0  ...           88.666667           5.773503           96.666667   \n",
       "3921   94.0  ...           90.000000           7.211103           96.666667   \n",
       "\n",
       "      Q15_rolling_std_3  Q16_rolling_mean_3  Q16_rolling_std_3  \\\n",
       "2              2.309401           95.000000           1.000000   \n",
       "3              2.645751           95.666667           0.577350   \n",
       "4              3.785939           94.333333           2.886751   \n",
       "5              3.605551           94.666667           3.214550   \n",
       "6              2.886751           93.333333           3.214550   \n",
       "...                 ...                 ...                ...   \n",
       "3917           2.081666           96.666667           3.214550   \n",
       "3918           2.081666           96.666667           3.214550   \n",
       "3919           2.516611           95.333333           5.507571   \n",
       "3920           3.055050           85.333333          14.843629   \n",
       "3921           3.055050           84.000000          13.228757   \n",
       "\n",
       "      Q17_rolling_mean_3  Q17_rolling_std_3  Q18_rolling_mean_3  \\\n",
       "2              96.000000           2.000000           88.666667   \n",
       "3              96.333333           2.081666           89.333333   \n",
       "4              97.000000           1.000000           90.000000   \n",
       "5              96.666667           0.577350           91.000000   \n",
       "6              95.666667           1.527525           92.333333   \n",
       "...                  ...                ...                 ...   \n",
       "3917           97.333333           2.081666           19.666667   \n",
       "3918           97.333333           2.081666           12.666667   \n",
       "3919           96.666667           3.214550           14.333333   \n",
       "3920           94.333333           3.214550           30.333333   \n",
       "3921           93.333333           1.527525           34.333333   \n",
       "\n",
       "      Q18_rolling_std_3  \n",
       "2              0.577350  \n",
       "3              1.527525  \n",
       "4              1.000000  \n",
       "5              1.000000  \n",
       "6              2.516611  \n",
       "...                 ...  \n",
       "3917          11.060440  \n",
       "3918           7.234178  \n",
       "3919          10.115994  \n",
       "3920          23.797759  \n",
       "3921          18.929694  \n",
       "\n",
       "[3920 rows x 60 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy of data with rolling avgs\n",
    "\n",
    "window = 3  \n",
    "df_rolling = df.copy()\n",
    "\n",
    "for col in df.columns:\n",
    "    if col not in ['Year', 'Pavement Rating']:\n",
    "        df_rolling[f'{col}_rolling_mean_{window}'] = df_rolling[col].rolling(window=window).mean()\n",
    "        df_rolling[f'{col}_rolling_std_{window}'] = df_rolling[col].rolling(window=window).std()\n",
    "\n",
    "df_rolling.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),  \n",
    "    (\"scaler\", RobustScaler()) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (df) - MAE: 0.3834 (±0.1017), R²: -0.5902 (±0.8413)\n",
      "Lag Data (df_lag) - MAE: 0.3721 (±0.0992), R²: -0.5092 (±0.7124)\n",
      "Rolling Data (df_rolling) - MAE: 67776056201.5699 (±135552112402.4827), R²: -604409889282383402762240.0000 (±1208819778564766805524480.0000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "y_df = df['average_rating']  \n",
    "X_df = df.drop(columns=['average_rating'])\n",
    "X_df_lag = df_lag.drop(columns=['average_rating'])\n",
    "y_lag = df_lag['average_rating']  \n",
    "X_df_rolling = df_rolling.drop(columns=['average_rating'])\n",
    "y_rolling = df_rolling['average_rating']  \n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "def evaluate_model(X, y, model, tscv, preprocessor):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    mae_scores = cross_val_score(pipeline, X, y, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "    r2_scores = cross_val_score(pipeline, X, y, cv=tscv, scoring='r2')\n",
    "    \n",
    "    return mae_scores, r2_scores\n",
    "\n",
    "mae_original, r2_original = evaluate_model(X_df, y_df, lr_model, tscv, preprocessor)\n",
    "mae_lag, r2_lag = evaluate_model(X_df_lag, y_lag, lr_model, tscv, preprocessor)\n",
    "mae_rolling, r2_rolling = evaluate_model(X_df_rolling, y_rolling, lr_model, tscv, preprocessor)\n",
    "\n",
    "print(f\"Original Data (df) - MAE: {-mae_original.mean():.4f} (±{mae_original.std():.4f}), R²: {r2_original.mean():.4f} (±{r2_original.std():.4f})\")\n",
    "print(f\"Lag Data (df_lag) - MAE: {-mae_lag.mean():.4f} (±{mae_lag.std():.4f}), R²: {r2_lag.mean():.4f} (±{r2_lag.std():.4f})\")\n",
    "print(f\"Rolling Data (df_rolling) - MAE: {-mae_rolling.mean():.4f} (±{mae_rolling.std():.4f}), R²: {r2_rolling.mean():.4f} (±{r2_rolling.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, we will use our data with lagged features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df_lag\n",
    "y = y_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit MAE: 0.3371 (±0.1085)\n",
      "TimeSeriesSplit R²: -0.1179 (±0.0936)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', rf_model)\n",
    "])\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "mae_scores_ts = cross_val_score(rf_pipeline, X, y, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "r2_scores_ts = cross_val_score(rf_pipeline, X, y, cv=tscv, scoring='r2')\n",
    "\n",
    "print(f\"TimeSeriesSplit MAE: {-mae_scores_ts.mean():.4f} (±{mae_scores_ts.std():.4f})\")\n",
    "print(f\"TimeSeriesSplit R²: {r2_scores_ts.mean():.4f} (±{r2_scores_ts.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from xgboost) (2.1.1)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-2.1.2-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost TimeSeriesSplit MAE: 0.4096 (±0.0900)\n",
      "XGBoost TimeSeriesSplit R²: -0.7692 (±0.6625)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "mae_scores_xgb = cross_val_score(xgb_pipeline, X, y, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "r2_scores_xgb = cross_val_score(xgb_pipeline, X, y, cv=tscv, scoring='r2')\n",
    "\n",
    "print(f\"XGBoost TimeSeriesSplit MAE: {-mae_scores_xgb.mean():.4f} (±{mae_scores_xgb.std():.4f})\")\n",
    "print(f\"XGBoost TimeSeriesSplit R²: {r2_scores_xgb.mean():.4f} (±{r2_scores_xgb.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR TimeSeriesSplit MAE: 0.3686 (±0.0879)\n",
      "SVR TimeSeriesSplit R²: -0.4272 (±0.3320)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_model = SVR()\n",
    "\n",
    "svr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', svr_model)\n",
    "])\n",
    "\n",
    "mae_scores_svr = cross_val_score(svr_pipeline, X, y, cv=tscv, scoring='neg_mean_absolute_error')\n",
    "r2_scores_svr = cross_val_score(svr_pipeline, X, y, cv=tscv, scoring='r2')\n",
    "\n",
    "print(f\"SVR TimeSeriesSplit MAE: {-mae_scores_svr.mean():.4f} (±{mae_scores_svr.std():.4f})\")\n",
    "print(f\"SVR TimeSeriesSplit R²: {r2_scores_svr.mean():.4f} (±{r2_scores_svr.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.9.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.0-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (362 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, astunparse, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.0 protobuf-5.28.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.0 wrapt-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3921, 39)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lag_clean = df_lag.dropna(subset=[col for col in df_lag.columns if 'lag' in col])\n",
    "\n",
    "X_clean = df_lag_clean.drop(columns=['average_rating'])\n",
    "y_clean = df_lag_clean['average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 21.6593\n",
      "Epoch 2/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6441\n",
      "Epoch 3/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6746 \n",
      "Epoch 4/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6241\n",
      "Epoch 5/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6214\n",
      "Epoch 6/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5727\n",
      "Epoch 7/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5827\n",
      "Epoch 8/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5546\n",
      "Epoch 9/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5406\n",
      "Epoch 10/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5409\n",
      "Epoch 11/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5693\n",
      "Epoch 12/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5382\n",
      "Epoch 13/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5196\n",
      "Epoch 14/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5249\n",
      "Epoch 15/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5126\n",
      "Epoch 16/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5189\n",
      "Epoch 17/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5155\n",
      "Epoch 18/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5364\n",
      "Epoch 19/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5550\n",
      "Epoch 20/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5498\n",
      "Epoch 21/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5047\n",
      "Epoch 22/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5048\n",
      "Epoch 23/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5274 \n",
      "Epoch 24/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5031\n",
      "Epoch 25/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5132 \n",
      "Epoch 26/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5216 \n",
      "Epoch 27/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4919\n",
      "Epoch 28/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4772\n",
      "Epoch 29/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5120 \n",
      "Epoch 30/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5313 \n",
      "Epoch 31/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4753 \n",
      "Epoch 32/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5356\n",
      "Epoch 33/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5272\n",
      "Epoch 34/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5080\n",
      "Epoch 35/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4922\n",
      "Epoch 36/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5085 \n",
      "Epoch 37/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5495\n",
      "Epoch 38/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4988\n",
      "Epoch 39/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4787\n",
      "Epoch 40/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4692\n",
      "Epoch 41/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4736 \n",
      "Epoch 42/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5028\n",
      "Epoch 43/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4827\n",
      "Epoch 44/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4841\n",
      "Epoch 45/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5126\n",
      "Epoch 46/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4662\n",
      "Epoch 47/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4979\n",
      "Epoch 48/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5017\n",
      "Epoch 49/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4899\n",
      "Epoch 50/50\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4660\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "MAE: 0.3200\n",
      "R²: -0.0692\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X_clean)\n",
    "\n",
    "def create_sequences(data, target, time_steps=1):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X_seq.append(data[i:i+time_steps])\n",
    "        y_seq.append(target[i+time_steps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "time_steps = 3 \n",
    "X_seq, y_seq = create_sequences(X_scaled, y_clean, time_steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, shuffle=False)\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=False, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1)) \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = create_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
